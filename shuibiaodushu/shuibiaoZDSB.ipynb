{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tutorial(1).ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vq9Btj4NelpQ","executionInfo":{"status":"ok","timestamp":1621304894276,"user_tz":-480,"elapsed":31603,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"d8e285a2-9fab-4a86-d26c-fca6eb463d74"},"source":["import os\n","from google.colab import  drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7L-vghFU3VRR","executionInfo":{"status":"ok","timestamp":1621304897989,"user_tz":-480,"elapsed":1750,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"65aeeffb-4e24-4bf2-92bc-df32395367cf"},"source":["%cd drive/MyDrive/mode/"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/mode\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NUspbU3TrIE-","executionInfo":{"status":"ok","timestamp":1621304927741,"user_tz":-480,"elapsed":3282,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"168066ff-38aa-476d-8539-8d300334cbf7"},"source":["# !pip install pyclipper shapely \n","!pip install imgaug==0.4.0 pyclipper shapely\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: imgaug==0.4.0 in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: pyclipper in /usr/local/lib/python3.7/dist-packages (1.2.1)\n","Requirement already satisfied: shapely in /usr/local/lib/python3.7/dist-packages (1.7.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.4.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.15.0)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (1.19.5)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (2.4.1)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (0.16.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (4.1.2.30)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug==0.4.0) (3.2.2)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (2.5.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug==0.4.0) (1.1.1)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.4.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (1.3.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug==0.4.0) (2.8.1)\n","Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug==0.4.0) (4.4.2)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"aoarI14urVMs"},"source":["# 统一导入工具包\n","import os\n","import warnings\n","import torch\n","import torch.nn as nn\n","import torchvision\n","import torch.nn.functional as F\n","import torch.utils.data as data\n","import numpy as np\n","import cv2\n","import math\n","import pyclipper\n","import imgaug\n","import imgaug.augmenters as iaa\n","\n","from PIL import Image\n","from shapely.geometry import Polygon\n","from collections import OrderedDict\n","from tqdm import tqdm\n","from torchvision import transforms\n","\n","%matplotlib inline\n","import matplotlib\n","import matplotlib.pyplot as plt\n","\n","\n","# 是否使用 GPU\n","if torch.cuda.is_available():\n","    device = torch.device('cuda')\n","else:\n","    device = torch.device('cpu')\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7hvvB045rjcb"},"source":["# 参数设置\n","class DetOptions():\n","    def __init__(self):\n","        self.lr = 0.004\n","        self.max_epoch =100\n","        self.batch_size = 8\n","        self.num_workers = 8\n","        self.print_interval = 100\n","        self.save_interval = 100\n","        self.train_dir = 'datasets/data/train_imgs'\n","        self.train_gt_dir = 'datasets/data/train_gts'                 \n","        self.test_dir = 'datasets/data/test_imgs'\n","        self.save_dir = 'temp/det_models/'                            # 保存检测模型\n","        self.saved_model_path = 'temp/det_models/checkpoint_final'    # 保存最终检测模型\n","        self.det_res_dir = 'temp/det_res/'                            # 保存测试集检测结\n","        self.thresh = 0.3                                             # 分割后处理阈值\n","        self.box_thresh = 0.5                                         # 检测框阈值\n","        self.max_candidates = 10                                      # 候选检测框数量（本数据集每张图像只有一个文本，因此可置为1）\n","        self.test_img_short_side = 640                                # 测试图像最短边长度\n","\n","det_args = DetOptions()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X-GHoBXSrra8"},"source":["'''\n","数据增强变换方法\n","'''\n","class BaseAugment():\n","    '''\n","    通过 imgaug.augmenters 进行基础变换，包括尺寸调整、翻转、旋转等\n","    '''\n","    def __init__(self, only_resize=False, keep_ratio=False, augmenters=None, resize_shape=None):\n","        self.only_resize = only_resize\n","        self.keep_ratio = keep_ratio\n","        self.augmenter = augmenters\n","        self.resize_shape = resize_shape\n","\n","    def resize_image(self, image):\n","        origin_height, origin_width, _ = image.shape\n","        height = self.resize_shape['height']\n","        width = self.resize_shape['width']\n","        if self.keep_ratio:    # 是否保持图像长宽比不变\n","            width = origin_width * height / origin_height\n","            N = math.ceil(width / 32)\n","            width = N * 32\n","        image = cv2.resize(image, (width, height))\n","        return image\n","    \n","    def process(self, data):\n","        image = data['image']\n","        shape = image.shape\n","\n","        if self.augmenter:\n","            aug = self.augmenter.to_deterministic()\n","            if self.only_resize:\n","                data['image'] = self.resize_image(image)   # 只进行尺寸调整\n","            else:\n","                data['image'] = aug.augment_image(image)   # 图像变换\n","            self.may_augment_annotation(aug, data, shape)  # 对 polygon 标注进行对应的变换\n","\n","        filename = data.get('filename', data.get('data_id', ''))\n","        data.update(filename=filename, shape=shape[:2])\n","        return data\n","        \n","    def may_augment_annotation(self, aug, data, shape):\n","        if aug is None:\n","            return data\n","\n","        line_polys = []\n","        for line in data['lines']:\n","            if self.only_resize:\n","                new_poly = [(p[0], p[1]) for p in line['poly']]\n","            else:\n","                new_poly = self.may_augment_poly(aug, shape, line['poly'])\n","            line_polys.append({\n","                'points': new_poly,\n","                'ignore': line['text'] == '###',    # 图像是否是困难样本（模糊不可辨），本任务数据集中不存在困难样本\n","                'text': line['text'],\n","            })\n","        data['polys'] = line_polys\n","        return data\n","\n","    def may_augment_poly(self, aug, img_shape, poly):\n","        keypoints = [imgaug.Keypoint(p[0], p[1]) for p in poly]\n","        keypoints = aug.augment_keypoints([imgaug.KeypointsOnImage(keypoints, shape=img_shape)])[0].keypoints\n","        poly = [(p.x, p.y) for p in keypoints]\n","        return poly\n","    \n","    \n","class ColorJitter():\n","    '''\n","    颜色增强，包括亮度、对比度、饱和度、色相变换\n","    '''\n","    def __init__(self, b=0.2, c=0.2, s=0.15, h=0.15):\n","        self.color_jitter = torchvision.transforms.ColorJitter(\n","            brightness=b, contrast=c, saturation=s, hue=h)\n","    def process(self, data):\n","        img = data['image']\n","        image = Image.fromarray(img.astype('uint8')).convert('RGB')   # 数据类型转换\n","        img = np.array(self.color_jitter(image)).astype(np.float64)\n","        data['image'] = img\n","        return data\n","    \n","\n","class RandomCropData():\n","    '''\n","    随机裁剪图像，并保证裁剪时不切割到图像中的文字区域\n","    '''\n","    def __init__(self, size=(640, 640)):\n","        self.size = size\n","        self.max_tries = 10             # 裁剪尝试的最大次数（因为存在裁剪区域太小等裁剪失败情况）\n","        self.min_crop_side_ratio = 0.1  # 裁剪区域边长最小比例，即裁剪的图像边长与原始图像边长的比值不能小于 min_crop_side_ratio\n","        \n","    def process(self, data):\n","        img = data['image']\n","\n","        ori_img = img\n","        ori_lines = data['polys']\n","        all_care_polys = [line['points'] for line in data['polys'] if not line['ignore']]\n","        crop_x, crop_y, crop_w, crop_h = self.crop_area(img, all_care_polys)   # 裁剪区域的左上角坐标(x, y)以及区域宽高(w, h)\n","        \n","        # 根据裁剪区域参数对图像进行裁剪，并填充空白以得到指定 size 的图像（在右侧或者底侧进行填充）\n","        scale_w = self.size[0] / crop_w\n","        scale_h = self.size[1] / crop_h\n","        scale = min(scale_w, scale_h)\n","        h = int(crop_h * scale)\n","        w = int(crop_w * scale)\n","        padimg = np.zeros((self.size[1], self.size[0], img.shape[2]), img.dtype)\n","        padimg[:h, :w] = cv2.resize(img[crop_y:crop_y + crop_h, crop_x:crop_x + crop_w], (w, h))\n","        img = padimg\n","        \n","        # 根据裁剪区域参数对文字位置坐标进行转换\n","        lines = []\n","        for line in data['polys']:\n","            poly = ((np.array(line['points']) - (crop_x, crop_y)) * scale).tolist()\n","            if not self.is_poly_outside_rect(poly, 0, 0, w, h): lines.append({**line, 'points': poly}) # 不保留裁剪区域之外的文字\n","        \n","        data['polys'] = lines\n","        data['image'] = img\n","\n","        return data\n","\n","\n","    def is_poly_outside_rect(self, poly, x, y, w, h):\n","        # 判断文字polygon 是否在矩形区域外\n","        poly = np.array(poly)\n","        if poly[:, 0].max() < x or poly[:, 0].min() > x + w:\n","            return True\n","        if poly[:, 1].max() < y or poly[:, 1].min() > y + h:\n","            return True\n","        return False\n","\n","    def split_regions(self, axis):\n","        # 返回可划切割线的连续区域\n","        regions = []\n","        min_axis = 0\n","        for i in range(1, axis.shape[0]):\n","            if axis[i] != axis[i-1] + 1:\n","                region = axis[min_axis:i]\n","                min_axis = i\n","                regions.append(region)\n","        return regions\n","\n","    def random_select(self, axis, max_size):\n","        # 从一块连续区域中选择两条切割线\n","        xx = np.random.choice(axis, size=2)\n","        xmin = np.min(xx)\n","        xmax = np.max(xx)\n","        xmin = np.clip(xmin, 0, max_size - 1)\n","        xmax = np.clip(xmax, 0, max_size - 1)\n","        return xmin, xmax\n","\n","    def region_wise_random_select(self, regions, max_size):\n","        # 从两块连续区域中选择两条切割线\n","        selected_index = list(np.random.choice(len(regions), 2))\n","        selected_values = []\n","        for index in selected_index:\n","            axis = regions[index]\n","            xx = int(np.random.choice(axis, size=1))\n","            selected_values.append(xx)\n","        xmin = min(selected_values)\n","        xmax = max(selected_values)\n","        return xmin, xmax\n","\n","    def crop_area(self, img, polys):\n","        # 裁剪区域\n","        h, w, _ = img.shape\n","        h_array = np.zeros(h, dtype=np.int32)\n","        w_array = np.zeros(w, dtype=np.int32)\n","        for points in polys:\n","            points = np.round(points, decimals=0).astype(np.int32)\n","            minx = np.min(points[:, 0])\n","            maxx = np.max(points[:, 0])\n","            w_array[minx:maxx] = 1\n","            miny = np.min(points[:, 1])\n","            maxy = np.max(points[:, 1])\n","            h_array[miny:maxy] = 1\n","        # h_array == 1 的位置表示有文本，h_array == 0 的位置表示无文本；w_array 同理\n","        h_axis = np.where(h_array == 0)[0]\n","        w_axis = np.where(w_array == 0)[0]\n","\n","        if len(h_axis) == 0 or len(w_axis) == 0:\n","            return 0, 0, w, h\n","\n","        h_regions = self.split_regions(h_axis)\n","        w_regions = self.split_regions(w_axis)\n","\n","        for i in range(self.max_tries):\n","            if len(w_regions) > 1:\n","                # 有多块可切割区域时\n","                xmin, xmax = self.region_wise_random_select(w_regions, w)\n","            else:\n","                # 只有一块可切割区域时\n","                xmin, xmax = self.random_select(w_axis, w)\n","            if len(h_regions) > 1:\n","                ymin, ymax = self.region_wise_random_select(h_regions, h)\n","            else:\n","                ymin, ymax = self.random_select(h_axis, h)\n","\n","            if xmax - xmin < self.min_crop_side_ratio * w or ymax - ymin < self.min_crop_side_ratio * h:\n","                # 切割区域太小，不可取\n","                continue\n","            num_poly_in_rect = 0\n","            \n","            # 保证至少有一个文字区域在切割出的区域中即可\n","            for poly in polys:\n","                if not self.is_poly_outside_rect(poly, xmin, ymin, xmax - xmin, ymax - ymin):\n","                    num_poly_in_rect += 1\n","                    break\n","\n","            if num_poly_in_rect > 0:\n","                return xmin, ymin, xmax - xmin, ymax - ymin\n","\n","        return 0, 0, w, h\n","    \n","\n","\n","class MakeSegDetectionData():\n","    '''\n","    构造文本区域二值图（DB论文中的 probability map），以及用于计算loss的mask\n","    '''\n","    def __init__(self, min_text_size=8, shrink_ratio=0.4):\n","        self.min_text_size = min_text_size\n","        self.shrink_ratio = shrink_ratio      # polygon 收缩比例\n","\n","    def process(self, data):\n","        # 数据结构调整统一，方便后续操作\n","        polygons = []\n","        ignore_tags = []\n","        annotations = data['polys']\n","        for annotation in annotations:\n","            polygons.append(np.array(annotation['points']))\n","            ignore_tags.append(annotation['ignore'])\n","        ignore_tags = np.array(ignore_tags, dtype=np.uint8)\n","        filename = data.get('filename', data['data_id'])\n","        shape = np.array(data['shape'])\n","        data = OrderedDict(image=data['image'],\n","                           polygons=polygons,\n","                           ignore_tags=ignore_tags,\n","                           shape=shape,\n","                           filename=filename,\n","                           is_training=data['is_training'])\n","    \n","        image = data['image']\n","        polygons = data['polygons']\n","        ignore_tags = data['ignore_tags']\n","        image = data['image']\n","        filename = data['filename']\n","\n","        h, w = image.shape[:2]\n","        if data['is_training']:\n","            polygons, ignore_tags = self.validate_polygons(polygons, ignore_tags, h, w)\n","        gt = np.zeros((h, w), dtype=np.float32)\n","        mask = np.ones((h, w), dtype=np.float32)\n","        for i in range(len(polygons)):\n","            polygon = polygons[i]\n","            height = max(polygon[:, 1]) - min(polygon[:, 1])\n","            width = max(polygon[:, 0]) - min(polygon[:, 0])\n","            if ignore_tags[i] or min(height, width) < self.min_text_size: # 文本区域太小时，作为困难样本 ignore\n","                cv2.fillPoly(mask, polygon.astype(np.int32)[np.newaxis, :, :], 0)\n","                ignore_tags[i] = True\n","            else:\n","                # 收缩 polygon 并绘制 probability map\n","                polygon_shape = Polygon(polygon)\n","                distance = polygon_shape.area * (1 - np.power(self.shrink_ratio, 2)) / polygon_shape.length\n","                subject = [tuple(l) for l in polygons[i]]\n","                padding = pyclipper.PyclipperOffset()\n","                padding.AddPath(subject, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n","                shrinked = padding.Execute(-distance)\n","                if shrinked == []:\n","                    cv2.fillPoly(mask, polygon.astype(np.int32)[np.newaxis, :, :], 0)\n","                    ignore_tags[i] = True\n","                    continue\n","                shrinked = np.array(shrinked[0]).reshape(-1, 2)\n","                cv2.fillPoly(gt, [shrinked.astype(np.int32)], 1)\n","\n","        if filename is None:\n","            filename = ''\n","        data.update(image=image,\n","                    polygons=polygons,\n","                    gt=gt, mask=mask, filename=filename)\n","        return data\n","\n","    \n","    def validate_polygons(self, polygons, ignore_tags, h, w):\n","        '''\n","        统一polygon坐标顺序，并且ignore面积为0的polygons\n","        '''\n","        if len(polygons) == 0:\n","            return polygons, ignore_tags\n","        assert len(polygons) == len(ignore_tags)\n","        for polygon in polygons:\n","            polygon[:, 0] = np.clip(polygon[:, 0], 0, w - 1)\n","            polygon[:, 1] = np.clip(polygon[:, 1], 0, h - 1)\n","\n","        for i in range(len(polygons)):\n","            area = self.polygon_area(polygons[i])\n","            if abs(area) < 1:\n","                ignore_tags[i] = True\n","            if area > 0:\n","                polygons[i] = polygons[i][::-1, :]   # 调整坐标顺序\n","        return polygons, ignore_tags\n","\n","    def polygon_area(self, polygon):\n","        edge = 0\n","        for i in range(polygon.shape[0]):\n","            next_index = (i + 1) % polygon.shape[0]\n","            edge += (polygon[next_index, 0] - polygon[i, 0]) * (polygon[next_index, 1] + polygon[i, 1])\n","\n","        return edge / 2.\n","\n","\n","\n","class MakeBorderMap():\n","    '''\n","    构造文本边界二值图（DB论文中的 threshold map），以及用于计算loss的mask\n","    '''\n","    def __init__(self, shrink_ratio=0.4, thresh_min=0.3, thresh_max=0.7):\n","        self.shrink_ratio = shrink_ratio\n","        self.thresh_min = thresh_min\n","        self.thresh_max = thresh_max\n","        warnings.simplefilter(\"ignore\")\n","\n","    def process(self, data):\n","        image = data['image']\n","        polygons = data['polygons']\n","        ignore_tags = data['ignore_tags']\n","        canvas = np.zeros(image.shape[:2], dtype=np.float32)\n","        mask = np.zeros(image.shape[:2], dtype=np.float32)\n","\n","        for i in range(len(polygons)):\n","            if ignore_tags[i]:\n","                continue\n","            self.draw_border_map(polygons[i], canvas, mask=mask)    # 绘制 border map\n","        canvas = canvas * (self.thresh_max - self.thresh_min) + self.thresh_min\n","        data['thresh_map'] = canvas\n","        data['thresh_mask'] = mask\n","        return data\n","\n","    def draw_border_map(self, polygon, canvas, mask):\n","        polygon = np.array(polygon)\n","        assert polygon.ndim == 2\n","        assert polygon.shape[1] == 2\n","\n","        polygon_shape = Polygon(polygon)\n","        distance = polygon_shape.area * (1 - np.power(self.shrink_ratio, 2)) / polygon_shape.length\n","        subject = [tuple(l) for l in polygon]\n","        padding = pyclipper.PyclipperOffset()\n","        padding.AddPath(subject, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n","        padded_polygon = np.array(padding.Execute(distance)[0])\n","        cv2.fillPoly(mask, [padded_polygon.astype(np.int32)], 1.0)\n","\n","        xmin = padded_polygon[:, 0].min()\n","        xmax = padded_polygon[:, 0].max()\n","        ymin = padded_polygon[:, 1].min()\n","        ymax = padded_polygon[:, 1].max()\n","        width = xmax - xmin + 1\n","        height = ymax - ymin + 1\n","\n","        polygon[:, 0] = polygon[:, 0] - xmin\n","        polygon[:, 1] = polygon[:, 1] - ymin\n","\n","        xs = np.broadcast_to(np.linspace(0, width - 1, num=width).reshape(1, width), (height, width))\n","        ys = np.broadcast_to(np.linspace(0, height - 1, num=height).reshape(height, 1), (height, width))\n","\n","        distance_map = np.zeros((polygon.shape[0], height, width), dtype=np.float32)\n","        for i in range(polygon.shape[0]):\n","            j = (i + 1) % polygon.shape[0]\n","            absolute_distance = self.distance(xs, ys, polygon[i], polygon[j])\n","            distance_map[i] = np.clip(absolute_distance / distance, 0, 1)\n","        distance_map = distance_map.min(axis=0)\n","\n","        xmin_valid = min(max(0, xmin), canvas.shape[1] - 1)\n","        xmax_valid = min(max(0, xmax), canvas.shape[1] - 1)\n","        ymin_valid = min(max(0, ymin), canvas.shape[0] - 1)\n","        ymax_valid = min(max(0, ymax), canvas.shape[0] - 1)\n","        canvas[ymin_valid:ymax_valid + 1, xmin_valid:xmax_valid + 1] = np.fmax(\n","            1 - distance_map[\n","                ymin_valid-ymin:ymax_valid-ymax+height,\n","                xmin_valid-xmin:xmax_valid-xmax+width],\n","            canvas[ymin_valid:ymax_valid + 1, xmin_valid:xmax_valid + 1])\n","\n","    def distance(self, xs, ys, point_1, point_2):\n","        # 计算图像中的点到 文字polygon 边界的距离\n","        height, width = xs.shape[:2]\n","        square_distance_1 = np.square(\n","            xs - point_1[0]) + np.square(ys - point_1[1])\n","        square_distance_2 = np.square(\n","            xs - point_2[0]) + np.square(ys - point_2[1])\n","        square_distance = np.square(\n","            point_1[0] - point_2[0]) + np.square(point_1[1] - point_2[1])\n","\n","        cosin = (square_distance - square_distance_1 - square_distance_2) / (2 * np.sqrt(square_distance_1 * square_distance_2))\n","        square_sin = 1 - np.square(cosin)\n","        square_sin = np.nan_to_num(square_sin)\n","        result = np.sqrt(square_distance_1 * square_distance_2 * square_sin / square_distance)\n","\n","        result[cosin < 0] = np.sqrt(np.fmin(square_distance_1, square_distance_2))[cosin < 0]\n","        return result\n","\n","    \n","class NormalizeImage():\n","    '''\n","    将图像元素值归一化到[-1, 1]\n","    '''\n","    RGB_MEAN = np.array([122.67891434, 116.66876762, 104.00698793])\n","\n","    def process(self, data):\n","        assert 'image' in data, '`image` in data is required by this process'\n","        image = data['image']\n","        image -= self.RGB_MEAN\n","        image /= 255.\n","        image = torch.from_numpy(image).permute(2, 0, 1).float()\n","        data['image'] = image\n","        return data\n","    \n","    @classmethod\n","    def restore(self, image):\n","        image = image.permute(1, 2, 0).to('cpu').numpy()\n","        image = image * 255.\n","        image += self.RGB_MEAN\n","        image = image.astype(np.uint8)\n","        return image\n","    \n","    \n","class FilterKeys():\n","    '''\n","    过滤掉后续不需要的键值对\n","    '''\n","    def __init__(self, superfluous):\n","        self.superfluous_keys = set(superfluous)\n","        \n","    def process(self, data):\n","        for key in self.superfluous_keys:\n","            del data[key]\n","        return data\n","\n","\n","# 训练集数据处理\n","train_processes = [             \n","    BaseAugment(only_resize=False, keep_ratio=False, \n","        augmenters=iaa.Sequential([\n","            iaa.Fliplr(0.5),               # 水平翻转\n","            iaa.Affine(rotate=(-10, 10)),  # 旋转\n","            iaa.Resize((0.5, 3.0))         # 尺寸调整\n","        ])),\n","    ColorJitter(),                         # 颜色增强\n","    RandomCropData(size=[640, 640]),       # 随机裁剪\n","    MakeSegDetectionData(),                # 构造 probability map\n","    MakeBorderMap(),                       # 构造 threshold map\n","    NormalizeImage(),                      # 归一化\n","    FilterKeys(superfluous=['polygons', 'filename', 'shape', 'ignore_tags', 'is_training']),    # 过滤多余元素\n","]\n","\n","\n","'''\n","数据集导入方法\n","'''\n","# dataset\n","class ImageDataset(data.Dataset):\n","    def __init__(self, data_dir=None, gt_dir=None, is_training=True, processes=None):\n","        self.data_dir = data_dir\n","        self.gt_dir = gt_dir\n","        self.is_training = is_training\n","        self.processes = processes\n","\n","        self.image_paths = []\n","        self.gt_paths = []\n","\n","        image_list = os.listdir(self.data_dir)\n","        self.image_paths = [self.data_dir + '/' + t for t in image_list]\n","        self.gt_paths = [self.gt_dir + '/' + t.replace('.jpg', '.txt') for t in image_list]\n","        self.targets = self.load_ann()      # 导入标注信息\n","\n","    def load_ann(self):\n","        res = []\n","        for gt in self.gt_paths:\n","            lines = []\n","            reader = open(gt, 'r').readlines()\n","            for line in reader:\n","                item = {}\n","                line = line.strip().split()\n","                poly = np.array(list(map(float, line[:8]))).reshape((-1, 2)).tolist()\n","                item['poly'] = poly\n","                item['text'] = line[8]   # 前8为 polygon 坐标，第9是文本字符串\n","                lines.append(item)\n","            res.append(lines)\n","        return res\n","\n","    def __getitem__(self, index):\n","        if index >= len(self.image_paths):\n","            index = index % len(self.image_paths)\n","        data = {}\n","        image_path = self.image_paths[index]\n","        \n","        img = cv2.imread(image_path, cv2.IMREAD_COLOR).astype('float32')\n","        target = self.targets[index]\n","        \n","        data['filename'] = image_path.split('/')[-1]\n","        data['data_id'] = image_path.split('/')[-1]\n","        data['image'] = img\n","        data['lines'] = target\n","        data['is_training'] = self.is_training\n","        if self.processes is not None:\n","            for data_process in self.processes:    # 做数据增强\n","                data = data_process.process(data)\n","        return data\n","\n","    def __len__(self):\n","        return len(self.image_paths)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XPVVVz1yt63T"},"source":["# BCE loss 计算 probability map 损失\n","class BalanceCrossEntropyLoss(nn.Module):\n","    def __init__(self, negative_ratio=3.0, eps=1e-6):\n","        super(BalanceCrossEntropyLoss, self).__init__()\n","        self.negative_ratio = negative_ratio\n","        self.eps = eps\n","\n","    def forward(self, pred, gt, mask):\n","        if pred.dim() == 4:\n","            pred = pred[:, 0, :, :]\n","        positive = (gt * mask).byte()\n","        negative = ((1 - gt) * mask).byte()\n","        positive_count = int(positive.float().sum())\n","        negative_count = min(int(negative.float().sum()), int(positive_count * self.negative_ratio))\n","        loss = nn.functional.binary_cross_entropy(pred, gt, reduction='none')\n","        positive_loss = loss * positive.float()\n","        negative_loss = loss * negative.float()\n","        negative_loss, _ = torch.topk(negative_loss.view(-1), negative_count)\n","\n","        balance_loss = (positive_loss.sum() + negative_loss.sum()) / (positive_count + negative_count + self.eps)\n","        return balance_loss\n","\n","\n","# MaskL1Loss 计算 threshold map 损失\n","class MaskL1Loss(nn.Module):\n","    def __init__(self):\n","        super(MaskL1Loss, self).__init__()\n","\n","    def forward(self, pred, gt, mask):\n","        mask_sum = mask.sum()\n","        if mask_sum.item() == 0:\n","            return mask_sum\n","        else:\n","            loss = (torch.abs(pred[:, 0] - gt) * mask).sum() / mask_sum\n","            return loss\n","\n","\n","# DiceLoss 计算 approximate binary map 损失\n","class DiceLoss(nn.Module):\n","    '''\n","    Loss function from https://arxiv.org/abs/1707.03237\n","    '''\n","    def __init__(self, eps=1e-6):\n","        super(DiceLoss, self).__init__()\n","        self.eps = eps\n","\n","    def forward(self, pred, gt, mask):\n","        if pred.dim() == 4:\n","            pred = pred[:, 0, :, :]\n","        assert pred.shape == gt.shape\n","        assert pred.shape == mask.shape\n","\n","        intersection = (pred * gt * mask).sum()\n","        union = (pred * mask).sum() + (gt * mask).sum() + self.eps\n","        loss = 1 - 2.0 * intersection / union\n","        return loss\n","    \n","\n","class L1BalanceCELoss(nn.Module):\n","    def __init__(self, eps=1e-6, l1_scale=10, bce_scale=1):\n","        super(L1BalanceCELoss, self).__init__()\n","        self.dice_loss = DiceLoss(eps=eps)\n","        self.l1_loss = MaskL1Loss()\n","        self.bce_loss = BalanceCrossEntropyLoss()\n","\n","        self.l1_scale = l1_scale        # 不同损失赋予不同权重\n","        self.bce_scale = bce_scale\n","\n","    def forward(self, pred, batch):\n","        metrics = dict()\n","        bce_loss = self.bce_loss(pred['binary'], batch['gt'], batch['mask'])\n","        l1_loss = self.l1_loss(pred['thresh'], batch['thresh_map'], batch['thresh_mask'])\n","        dice_loss = self.dice_loss(pred['thresh_binary'], batch['gt'], batch['mask'])\n","        \n","        loss = dice_loss + self.l1_scale * l1_loss + bce_loss * self.bce_scale    \n","        metrics['binary_loss'] = bce_loss\n","        metrics['thresh_loss'] = l1_loss\n","        metrics['thresh_binary_loss'] = dice_loss\n","        \n","        return loss, metrics"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"coaRVx92t9LK"},"source":["'''\n","Backbone\n","'''\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(planes * 4)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        \n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block=Bottleneck, layers=[3, 4, 6, 3], num_classes=1000):\n","        super(ResNet, self).__init__()\n","        self.inplanes = 64\n","        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","    \n","        self.smooth = nn.Conv2d(2048, 256, kernel_size=1, stride=1, padding=1)    \n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2. / n))\n","            elif isinstance(m, nn.BatchNorm2d):\n","                m.weight.data.fill_(1)\n","                m.bias.data.zero_()\n","\n","    def _make_layer(self, block, planes, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.inplanes, planes))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x2 = self.layer1(x)\n","        x3 = self.layer2(x2)\n","        x4 = self.layer3(x3)\n","        x5 = self.layer4(x4)\n","\n","        return x2, x3, x4, x5\n","   \n","\n","'''\n","Decoder\n","'''\n","class SegDetector(nn.Module):\n","    def __init__(self, in_channels=[256, 512, 1024, 2048], inner_channels=256, k=50, bias=False):\n","        super(SegDetector, self).__init__()\n","        self.k = k\n","        self.up5 = nn.Upsample(scale_factor=2, mode='nearest')\n","        self.up4 = nn.Upsample(scale_factor=2, mode='nearest')\n","        self.up3 = nn.Upsample(scale_factor=2, mode='nearest')\n","\n","        self.in5 = nn.Conv2d(in_channels[-1], inner_channels, 1, bias=bias)\n","        self.in4 = nn.Conv2d(in_channels[-2], inner_channels, 1, bias=bias)\n","        self.in3 = nn.Conv2d(in_channels[-3], inner_channels, 1, bias=bias)\n","        self.in2 = nn.Conv2d(in_channels[-4], inner_channels, 1, bias=bias)\n","\n","        self.out5 = nn.Sequential(\n","            nn.Conv2d(inner_channels, inner_channels // 4, 3, padding=1, bias=bias),\n","            nn.Upsample(scale_factor=8, mode='nearest'))\n","        self.out4 = nn.Sequential(\n","            nn.Conv2d(inner_channels, inner_channels // 4, 3, padding=1, bias=bias),\n","            nn.Upsample(scale_factor=4, mode='nearest'))\n","        self.out3 = nn.Sequential(\n","            nn.Conv2d(inner_channels, inner_channels // 4, 3, padding=1, bias=bias),\n","            nn.Upsample(scale_factor=2, mode='nearest'))\n","        self.out2 = nn.Conv2d(\n","            inner_channels, inner_channels//4, 3, padding=1, bias=bias)\n","\n","        self.binarize = nn.Sequential(\n","            nn.Conv2d(inner_channels, inner_channels // 4, 3, padding=1, bias=bias),\n","            nn.BatchNorm2d(inner_channels//4),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(inner_channels//4, inner_channels//4, 2, 2),\n","            nn.BatchNorm2d(inner_channels//4),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(inner_channels//4, 1, 2, 2),\n","            nn.Sigmoid())\n","        self.binarize.apply(self.weights_init)\n","\n","        self.thresh = nn.Sequential(\n","            nn.Conv2d(inner_channels, inner_channels // 4, 3, padding=1, bias=bias),\n","            nn.BatchNorm2d(inner_channels//4),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(inner_channels // 4, inner_channels // 4, 2, 2),\n","            nn.BatchNorm2d(inner_channels//4),\n","            nn.ReLU(inplace=True),\n","            nn.ConvTranspose2d(inner_channels // 4, 1, 2, 2),\n","            nn.Sigmoid())\n","        self.thresh.apply(self.weights_init)\n","\n","        self.in5.apply(self.weights_init)\n","        self.in4.apply(self.weights_init) \n","        self.in3.apply(self.weights_init)\n","        self.in2.apply(self.weights_init)\n","        self.out5.apply(self.weights_init)\n","        self.out4.apply(self.weights_init)\n","        self.out3.apply(self.weights_init)\n","        self.out2.apply(self.weights_init)\n","\n","    def weights_init(self, m):\n","        # 模型权重初始化\n","        classname = m.__class__.__name__\n","        if classname.find('Conv') != -1:\n","            nn.init.kaiming_normal_(m.weight.data)\n","        elif classname.find('BatchNorm') != -1:\n","            m.weight.data.fill_(1.)\n","            m.bias.data.fill_(1e-4)\n","\n","    def forward(self, features):\n","        c2, c3, c4, c5 = features\n","        in5 = self.in5(c5)\n","        in4 = self.in4(c4)\n","        in3 = self.in3(c3)\n","        in2 = self.in2(c2)\n","\n","        out4 = self.up5(in5) + in4   # 尺寸为输入图像的 1/16\n","        out3 = self.up4(out4) + in3  # 1/8\n","        out2 = self.up3(out3) + in2  # 1/4\n","\n","        p5 = self.out5(in5)\n","        p4 = self.out4(out4)\n","        p3 = self.out3(out3)\n","        p2 = self.out2(out2)\n","\n","        fuse = torch.cat((p5, p4, p3, p2), 1)    # 尺寸为 batch_size，64*4， H', W'\n","        binary = self.binarize(fuse)\n","        if self.training:\n","            result = OrderedDict(binary=binary)\n","            thresh = self.thresh(fuse)\n","            thresh_binary = self.step_function(binary, thresh)\n","            result.update(thresh=thresh, thresh_binary=thresh_binary)\n","            return result\n","        else:\n","            return binary    # for inference\n","\n","    def step_function(self, x, y):\n","        return torch.reciprocal(1 + torch.exp(-self.k * (x - y)))\n","    \n","\n","# 包装\n","class BasicModel(nn.Module):\n","    def __init__(self):\n","        nn.Module.__init__(self)\n","        self.backbone = ResNet()\n","        self.decoder = SegDetector()\n","\n","    def forward(self, data):\n","        output = self.backbone(data)\n","        output = self.decoder(output)\n","        return output\n","\n","class SegDetectorModel(nn.Module):\n","    def __init__(self, device):\n","        super(SegDetectorModel, self).__init__()\n","        self.model = BasicModel()\n","        self.criterion = L1BalanceCELoss()\n","        self.device = device\n","        self.to(self.device)\n","\n","    def forward(self, batch, training=True):\n","        for key, value in batch.items():\n","            if value is not None and hasattr(value, 'to'):\n","                batch[key] = value.to(self.device)\n","                \n","        pred = self.model(batch['image'].float())\n","\n","        if self.training:\n","            loss, metrics = self.criterion(pred, batch)    # 计算损失函数\n","            return pred, loss, metrics\n","        else:\n","            return pred"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7rOm7B99uagc"},"source":["# 学习率调整方法\n","class DecayLearningRate():\n","    def __init__(self, lr=0.004, epochs=200, factor=0.9):\n","        self.lr = lr\n","        self.epochs = epochs\n","        self.factor = factor\n","\n","    def get_learning_rate(self, epoch):\n","        # 学习率随着训练过程进行不断下降\n","        rate = np.power(1.0 - epoch / float(self.epochs + 1), self.factor)\n","        return rate * self.lr\n","    \n","    def update_learning_rate(self, optimizer, epoch):\n","        lr = self.get_learning_rate(epoch)\n","        for group in optimizer.param_groups:\n","            group['lr'] = lr\n","        return lr\n","\n","\n","# 检测模型训练\n","def det_train():\n","    # model\n","    model = SegDetectorModel(device)\n","\n","    # data_loader\n","    train_dataset = ImageDataset(data_dir=det_args.train_dir, gt_dir=det_args.train_gt_dir, is_training=True, processes=train_processes)\n","    train_dataloader = data.DataLoader(train_dataset, batch_size=det_args.batch_size, num_workers=det_args.num_workers, shuffle=True, drop_last=False)\n","    \n","    # initialize dataloader and scheduler\n","    optimizer = torch.optim.SGD(model.parameters(), lr=det_args.lr, momentum=0.9, weight_decay=1e-4)\n","    scheduler = DecayLearningRate(lr=det_args.lr, epochs=det_args.max_epoch)\n","\n","    step = 2\n","    epoch = 10\n","    model.train()\n","    os.makedirs(det_args.save_dir, exist_ok=True)\n","    for epoch in range(det_args.max_epoch):\n","        for batch in train_dataloader:\n","            step += 1\n","            current_lr = scheduler.update_learning_rate(optimizer, epoch)    # 学习率调整\n","\n","            optimizer.zero_grad()\n","            pred, loss, metrics = model.forward(batch, training=True)\n","            loss.backward()\n","            optimizer.step()\n","\n","            if step % det_args.print_interval == 0:\n","                line = []\n","                for key, l_val in metrics.items():\n","                    line.append('{0}: {1:.4f}'.format(key, l_val.mean()))\n","                line = '\\t'.join(line)\n","                info = '\\t'.join(['step:{:6d}', 'epoch:{:3d}', 'loss: {:4f}', '{}', 'lr: {:.4f}']).format(step, epoch, loss.item(), line, current_lr)\n","                print(info)\n","            \n","                    \n","        # 保存阶段模型\n","        if epoch % det_args.save_interval == 0:\n","            save_name = 'checkpoint_' + str(epoch)\n","            torch.save(model.state_dict(), os.path.join(det_args.save_dir, save_name))\n","      \n","\n","    # 保存最终模型\n","    torch.save(model.state_dict(), det_args.saved_model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2HDJ_e5uh11","executionInfo":{"status":"ok","timestamp":1621307821707,"user_tz":-480,"elapsed":2819384,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"d2f94781-99af-43b4-cea7-3e6d2e5677ff"},"source":["# 运行训练代码\n","det_train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["step:   100\tepoch:  0\tloss: 2.712286\tbinary_loss: 0.5795\tthresh_loss: 0.1133\tthresh_binary_loss: 1.0000\tlr: 0.0040\n","step:   200\tepoch:  1\tloss: 2.675507\tbinary_loss: 0.5697\tthresh_loss: 0.1106\tthresh_binary_loss: 1.0000\tlr: 0.0037\n","step:   300\tepoch:  2\tloss: 2.353370\tbinary_loss: 0.5718\tthresh_loss: 0.0784\tthresh_binary_loss: 0.9971\tlr: 0.0033\n","step:   400\tepoch:  3\tloss: 2.205625\tbinary_loss: 0.5752\tthresh_loss: 0.0705\tthresh_binary_loss: 0.9254\tlr: 0.0030\n","step:   500\tepoch:  3\tloss: 2.256022\tbinary_loss: 0.5725\tthresh_loss: 0.0798\tthresh_binary_loss: 0.8858\tlr: 0.0030\n","step:   600\tepoch:  4\tloss: 1.525655\tbinary_loss: 0.4941\tthresh_loss: 0.0611\tthresh_binary_loss: 0.4205\tlr: 0.0027\n","step:   700\tepoch:  5\tloss: 0.876736\tbinary_loss: 0.2946\tthresh_loss: 0.0439\tthresh_binary_loss: 0.1430\tlr: 0.0023\n","step:   800\tepoch:  6\tloss: 0.800443\tbinary_loss: 0.2132\tthresh_loss: 0.0465\tthresh_binary_loss: 0.1220\tlr: 0.0020\n","step:   900\tepoch:  7\tloss: 1.111031\tbinary_loss: 0.2931\tthresh_loss: 0.0598\tthresh_binary_loss: 0.2204\tlr: 0.0016\n","step:  1000\tepoch:  7\tloss: 0.698207\tbinary_loss: 0.1658\tthresh_loss: 0.0432\tthresh_binary_loss: 0.1003\tlr: 0.0016\n","step:  1100\tepoch:  8\tloss: 0.650766\tbinary_loss: 0.1539\tthresh_loss: 0.0391\tthresh_binary_loss: 0.1058\tlr: 0.0012\n","step:  1200\tepoch:  9\tloss: 0.564695\tbinary_loss: 0.1219\tthresh_loss: 0.0363\tthresh_binary_loss: 0.0799\tlr: 0.0009\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2k_mSozEvNQY"},"source":["# 从分割图得到最终文字坐标的后处理方法\n","class SegDetectorRepresenter():\n","    '''\n","    从 probability map 得到检测框的方法\n","    '''\n","    def __init__(self, thresh=0.3, box_thresh=0.7, max_candidates=100):\n","        self.thresh = thresh\n","        self.box_thresh = box_thresh\n","        self.max_candidates = max_candidates\n","        self.min_size = 3\n","        self.scale_ratio = 0.4\n","\n","    def represent(self, batch, pred):\n","        images = batch['image']\n","        segmentation = pred > self.thresh    # 将预测分割图进行二值化\n","        boxes_batch = []\n","        scores_batch = []\n","        for batch_index in range(images.size(0)):\n","            height, width = batch['shape'][batch_index]\n","            boxes, scores = self.polygons_from_bitmap(pred[batch_index], segmentation[batch_index], width, height)\n","            boxes_batch.append(boxes)\n","            scores_batch.append(scores)\n","        return boxes_batch, scores_batch\n","    \n","\n","    def polygons_from_bitmap(self, pred, _bitmap, dest_width, dest_height):\n","        assert _bitmap.size(0) == 1\n","        bitmap = _bitmap.cpu().numpy()[0]\n","        pred = pred.cpu().detach().numpy()[0]\n","        height, width = bitmap.shape\n","        boxes = []\n","        scores = []\n","\n","        contours, _ = cv2.findContours((bitmap*255).astype(np.uint8), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # 找分割轮廓\n","\n","        for contour in contours[:self.max_candidates]:\n","            epsilon = 0.01 * cv2.arcLength(contour, True)\n","            approx = cv2.approxPolyDP(contour, epsilon, True)      # 多边形拟合轮廓曲线\n","            points = approx.reshape((-1, 2))\n","            if points.shape[0] < 4:\n","                continue\n","            score = self.box_score_fast(pred, points.reshape(-1, 2))   # 计算分割区域的整体得分，去除低分候选区域\n","            if self.box_thresh > score:\n","                continue\n","            \n","            if points.shape[0] > 2:\n","                box = self.unclip(points, unclip_ratio=2.0)    # 因为得到的分割结果是文本收缩区域，因此需要进行一定程度扩张\n","                if len(box) != 1:\n","                    continue\n","            else:\n","                continue\n","                \n","            box = box.reshape(-1, 2)\n","            mini_box, sside = self.get_mini_boxes(box.reshape((-1, 1, 2)))   # 计算最小外接矩形\n","            if sside < self.min_size + 2:\n","                continue\n","\n","            if not isinstance(dest_width, int):\n","                dest_width = dest_width.item()\n","                dest_height = dest_height.item()\n","            \n","            mini_box[:, 0] = np.clip(np.round(mini_box[:, 0] / width * dest_width), 0, dest_width)       # 尺寸与原图对齐\n","            mini_box[:, 1] = np.clip(np.round(mini_box[:, 1] / height * dest_height), 0, dest_height)\n","            boxes.append(mini_box.tolist())\n","            scores.append(score)\n","        return boxes, scores\n","\n","\n","    def unclip(self, box, unclip_ratio=1.5):\n","        '''\n","        做一定程度的分割区域扩张\n","        '''\n","        poly = Polygon(box)\n","        distance = poly.area * unclip_ratio / poly.length\n","        offset = pyclipper.PyclipperOffset()\n","        offset.AddPath(box, pyclipper.JT_ROUND, pyclipper.ET_CLOSEDPOLYGON)\n","        expanded = np.array(offset.Execute(distance))\n","        return expanded\n","\n","    def get_mini_boxes(self, contour):\n","        bounding_box = cv2.minAreaRect(contour)\n","        points = sorted(list(cv2.boxPoints(bounding_box)), key=lambda x: x[0])\n","\n","        index_1, index_2, index_3, index_4 = 0, 1, 2, 3\n","        if points[1][1] > points[0][1]:\n","            index_1 = 0\n","            index_4 = 1\n","        else:\n","            index_1 = 1\n","            index_4 = 0\n","        if points[3][1] > points[2][1]:\n","            index_2 = 2\n","            index_3 = 3\n","        else:\n","            index_2 = 3\n","            index_3 = 2\n","\n","        box = np.array([points[index_1], points[index_2],\n","               points[index_3], points[index_4]]).reshape(4, 2)\n","        return box, min(bounding_box[1])\n","\n","    def box_score_fast(self, bitmap, _box):\n","        '''\n","        计算多边形检测区域的分数（多边形所包含的像素点预测为前景文本的分数的平均值）\n","        '''\n","        h, w = bitmap.shape[:2]\n","        box = _box.copy()\n","        xmin = np.clip(np.floor(box[:, 0].min()).astype(np.int), 0, w - 1)\n","        xmax = np.clip(np.ceil(box[:, 0].max()).astype(np.int), 0, w - 1)\n","        ymin = np.clip(np.floor(box[:, 1].min()).astype(np.int), 0, h - 1)\n","        ymax = np.clip(np.ceil(box[:, 1].max()).astype(np.int), 0, h - 1)\n","\n","        mask = np.zeros((ymax - ymin + 1, xmax - xmin + 1), dtype=np.uint8)\n","        box[:, 0] = box[:, 0] - xmin\n","        box[:, 1] = box[:, 1] - ymin\n","        cv2.fillPoly(mask, box.reshape(1, -1, 2).astype(np.int32), 1)\n","        return cv2.mean(bitmap[ymin:ymax+1, xmin:xmax+1], mask)[0]\n","    \n","# 测试图片处理\n","def resize_image(img):\n","    # 图像最短边设定为预设长度，长边根据原图尺寸比例进行缩放\n","    height, width, _ = img.shape\n","    if height < width:\n","        new_height = det_args.test_img_short_side\n","        new_width = int(math.ceil(new_height / height * width / 32) * 32)\n","    else:\n","        new_width = det_args.test_img_short_side\n","        new_height = int(math.ceil(new_width / width * height / 32) * 32)\n","    resized_img = cv2.resize(img, (new_width, new_height))\n","    return resized_img\n","    \n","def load_test_image(image_path):\n","    RGB_MEAN = np.array([122.67891434, 116.66876762, 104.00698793])\n","    img = cv2.imread(image_path, cv2.IMREAD_COLOR).astype('float32')\n","    original_shape = img.shape[:2]\n","    img = resize_image(img)\n","    img -= RGB_MEAN\n","    img /= 255.\n","    img = torch.from_numpy(img).permute(2, 0, 1).float().unsqueeze(0)\n","    return img, original_shape\n","\n","\n","# 检测结果输出\n","def format_output(det_res_dir, batch, output):\n","    batch_boxes, batch_scores = output\n","    for index in range(batch['image'].size(0)):\n","        original_shape = batch['shape'][index]\n","        filename = batch['filename'][index]\n","        result_file_name = 'det_res_' + filename.split('/')[-1].split('.')[0] + '.txt'\n","        result_file_path = os.path.join(det_res_dir, result_file_name)\n","        boxes = batch_boxes[index]\n","        scores = batch_scores[index]\n","        with open(result_file_path, 'wt') as res:\n","            for i, box in enumerate(boxes):\n","                box = np.array(box).reshape(-1).tolist()\n","                result = \",\".join([str(int(x)) for x in box])\n","                score = scores[i]\n","                res.write(result + ',' + str(score) + \"\\n\")      \n","\n","                \n","# 测试\n","def det_test():\n","    # 模型加载\n","    model = SegDetectorModel(device)\n","    model.load_state_dict(torch.load(det_args.saved_model_path, map_location=device), strict=False)\n","    model.eval()\n","    \n","    # 后处理\n","    representer = SegDetectorRepresenter(thresh=det_args.thresh, box_thresh=det_args.box_thresh, max_candidates=det_args.max_candidates)\n","    \n","    # 推理\n","    os.makedirs(det_args.det_res_dir, exist_ok=True)\n","    batch = dict()\n","    cnt = 0\n","    with torch.no_grad():\n","        for file in tqdm(os.listdir(det_args.test_dir)):\n","            img_path = os.path.join(det_args.test_dir, file)\n","            image, ori_shape = load_test_image(img_path)\n","            batch['image'] = image\n","            batch['shape'] = [ori_shape]\n","            batch['filename'] = [file]\n","            pred = model.forward(batch, training=False)\n","            output = representer.represent(batch, pred) \n","            format_output(det_args.det_res_dir, batch, output)\n","\n","            cnt += 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9N8Sh5BovaYp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621308145301,"user_tz":-480,"elapsed":284705,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"c2841559-acf7-40ef-893d-4a0ac7612469"},"source":["# 运行测试代码\n","det_test()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 500/500 [04:41<00:00,  1.78it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ZEK5AbghxWdD"},"source":["class RecOptions():\n","    def __init__(self):\n","        self.height = 32              # 图像尺寸\n","        self.width = 100         \n","        self.voc_size = 21            # 字符数量 '0123456789ABCDEFGHIJ' + 'PADDING'位\n","        self.decoder_sdim = 512\n","        self.max_len = 5              # 文本长度\n","        self.lr = 1.0\n","        self.milestones = [40, 60]    # 在第 40 和 60 个 epoch 训练时降低学习率\n","        self.max_epoch = 100\n","        self.batch_size = 64\n","        self.num_workers = 8\n","        self.print_interval = 1\n","        self.save_interval = 1\n","        self.train_dir = 'temp/rec_datasets/train_imgs'\n","        self.test_dir = 'temp/rec_datasets/test_imgs'\n","        self.save_dir = 'temp/rec_models/'\n","        self.saved_model_path = 'temp/rec_models/checkpoint_final'\n","        self.rec_res_dir = 'temp/rec_res/'\n","\n","    def set_(self, key, value):\n","        if hasattr(self, key):\n","            setattr(self, key, value)\n","\n","rec_args = RecOptions()\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pFnub0kjxZYn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621309638564,"user_tz":-480,"elapsed":20434,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"2bea8253-821b-4d1c-ecf6-d20d0dc55a6a"},"source":["'''\n","标签处理：定义新字符类处理半字符的情况，比如将'0-1半字符'归到'A'类，减小歧义\n","识别训练数据构造：从完整图像中裁剪出文本图像作为识别模型输入数据\n","'''\n","def PreProcess():\n","    EXT_CHARS = {\n","        '01': 'A', '12': 'B', '23': 'C', '34': 'D', '45': 'E',\n","        '56': 'F', '67': 'G', '78': 'H', '89': 'I', '09': 'J'\n","    }\n","\n","    train_dir = 'datasets/data/train_imgs'\n","    train_labels_dir = 'datasets/data/train_gts'\n","    word_save_dir = 'temp/rec_datasets/train_imgs'      # 保存识别训练数据集\n","\n","\n","    os.makedirs(word_save_dir, exist_ok=True)\n","    label_files = os.listdir(train_labels_dir)\n","    for label_file in tqdm(label_files):\n","        with open(os.path.join(train_labels_dir, label_file), 'r') as f:\n","            lines = f.readlines()\n","        line = lines[0].strip().split()\n","        locs = line[:8]\n","        words = line[8:]\n","        \n","        # 标签处理\n","        if len(words) == 1:\n","            ext_word = words[0]\n","        else:\n","            assert len(words) % 2 == 0\n","            ext_word = ''\n","            for i in range(len(words[0])):\n","                char_i = [word[i] for word in words]\n","                if len(set(char_i)) == 1:\n","                    ext_word += char_i[0]\n","                elif len(set(char_i)) == 2:\n","                    char_i = list(set(char_i))\n","                    char_i.sort()\n","                    char_i = ''.join(char_i)\n","                    ext_char_i = EXT_CHARS[char_i]\n","                    ext_word += ext_char_i\n","\n","        locs = [int(t) for t in line[:8]]\n","            \n","        # 将倾斜文字图像调整为水平图像\n","        x1, y1, x2, y2, x3, y3, x4, y4 = locs\n","        w = int(0.5 * (((x2-x1)**2+(y2-y1)**2)**0.5 + ((x4-x3)**2+(y4-y3)**2)**0.5))\n","        h = int(0.5 * (((x2-x3)**2+(y2-y3)**2)**0.5 + ((x4-x1)**2+(y4-y1)**2)**0.5))\n","        src_points = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], dtype='float32')\n","        dst_points = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype='float32')\n","        M = cv2.getPerspectiveTransform(src_points, dst_points)\n","        image = cv2.imread(os.path.join(train_dir, label_file.replace('.txt', '.jpg')))\n","        word_image = cv2.warpPerspective(image, M, (w, h))\n","        \n","        # save images\n","        cv2.imwrite(os.path.join(word_save_dir, label_file.replace('.txt', '')+'_'+ext_word+'.jpg'), word_image)\n","\n","\n","# 运行识别训练数据前处理代码 \n","PreProcess()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 1000/1000 [00:19<00:00, 51.36it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"T8E-aw2IyR2H"},"source":["'''\n","数据集导入方法\n","'''\n","# data\n","class WMRDataset(data.Dataset):\n","    def __init__(self, data_dir=None, max_len=5, resize_shape=(32, 100), train=True):\n","        super(WMRDataset, self).__init__()\n","        self.data_dir = data_dir\n","        self.max_len = max_len\n","        self.is_train = train\n","        \n","        self.targets = [[os.path.join(data_dir, t), t.split('_')[-1][:5]] for t in os.listdir(data_dir) if t.endswith('.jpg')]\n","        self.PADDING, self.char2id, self.id2char = self.gen_labelmap()\n","        \n","        # 数据增强\n","        self.transform = transforms.Compose([\n","            transforms.Resize(resize_shape),\n","            transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n","            # 可以添加更多的数据增强操作，比如 gaussian blur、shear 等\n","            transforms.ToTensor()\n","        ])\n","        \n","    def __len__(self):\n","        return len(self.targets)\n","    \n","    @staticmethod\n","    def gen_labelmap(charset='0123456789ABCDEFGHIJ'):\n","        # 构造字符和数字标签对应字典\n","        PADDING = 'PADDING'\n","        char2id = {t:idx for t, idx in zip(charset, range(1, 1+len(charset)))}\n","        char2id.update({PADDING:0})\n","        id2char = {v:k for k, v in char2id.items()}\n","        return PADDING, char2id, id2char\n","\n","    \n","    def __getitem__(self, index):\n","        assert index <= len(self), 'index range error'\n","        img_path = self.targets[index][0]\n","        word = self.targets[index][1]\n","        img = Image.open(img_path)\n","        \n","        label = np.full((self.max_len,), self.char2id[self.PADDING], dtype=np.int)\n","        label_list = []\n","        word = word[:self.max_len]\n","        for char in word:\n","            label_list.append(self.char2id[char])\n","            \n","        label_len = len(label_list)\n","        assert len(label_list) <= self.max_len\n","        label[:len(label_list)] = np.array(label_list)\n","        \n","        if self.transform is not None and self.is_train:\n","            img = self.transform(img)\n","            img.sub_(0.5).div_(0.5)\n","        \n","        label_len = np.array(label_len).astype(np.int32)\n","        label = np.array(label).astype(np.int32)\n","        \n","        return img, label, label_len        # 输出图像、文本标签、标签长度, 计算 CTC loss 需要后两者信息"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5tPYKjSPzqxU","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1621309439171,"user_tz":-480,"elapsed":886,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"78949cfc-6eb9-4612-9fcc-3a961664753a"},"source":["dataset = WMRDataset(rec_args.train_dir, max_len=5, resize_shape=(rec_args.height, rec_args.width), train=True)\n","train_dataloader = data.DataLoader(dataset, batch_size=2, shuffle=True, pin_memory=True, drop_last=False)\n","batch = next(iter(train_dataloader))\n","\n","image, label, label_len = batch\n","image = ((image[0].permute(1, 2, 0).to('cpu').numpy() * 0.5 + 0.5) * 255).astype(np.uint8)\n","plt.title('image')\n","plt.xticks([])\n","plt.yticks([])\n","plt.imshow(image)\n","        \n","label_digit = label[0].to('cpu').numpy().tolist()\n","label_str = ''.join([dataset.id2char[t] for t in label_digit if t > 0])\n","\n","print('label_digit: ', label_digit)\n","print('label_str: ', label_str)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["label_digit:  [1, 2, 2, 10, 3]\n","label_str:  01192\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"Q-V7m4k1zz0i"},"source":["# backbone\n","class _Block(nn.Module):\n","    def __init__(self, inplanes, planes, stride=1, downsample=None):\n","        super(_Block, self).__init__()\n","        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False)\n","        self.bn1 = nn.BatchNorm2d(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","        \n","    def forward(self, x):\n","        residual = x\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        \n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","            \n","        out += residual\n","        out = self.relu(out)\n","        return out\n","\n","\n","class RecBackbone(nn.Module):\n","    def __init__(self):\n","        super(RecBackbone, self).__init__()\n","        \n","        in_channels = 3\n","        self.layer0 = nn.Sequential(\n","            nn.Conv2d(in_channels, 32, kernel_size=(3, 3), stride=1, padding=1, bias=False),\n","            nn.BatchNorm2d(32),\n","            nn.ReLU(inplace=True))\n","        \n","        \n","        self.inplanes = 32\n","        self.layer1 = self._make_layer(32,  3, [2, 2]) # [16, 50]\n","        self.layer2 = self._make_layer(64,  4, [2, 2]) # [8, 25]\n","        self.layer3 = self._make_layer(128, 6, [2, 1]) # [4, 25]\n","        self.layer4 = self._make_layer(256, 6, [2, 1]) # [2, 25]\n","        self.layer5 = self._make_layer(512, 3, [2, 1]) # [1, 25]\n","    \n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","                \n","    def _make_layer(self, planes, blocks, stride):\n","        downsample = None\n","        if stride != [1, 1] or self.inplanes != planes:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(planes))\n","            \n","        layers = []\n","        layers.append(_Block(self.inplanes, planes, stride, downsample))\n","        self.inplanes = planes\n","        for _ in range(1, blocks):\n","            layers.append(_Block(self.inplanes, planes))\n","            return nn.Sequential(*layers)\n","        \n","        \n","    def forward(self, x):\n","        x0 = self.layer0(x)\n","        x1 = self.layer1(x0)\n","        x2 = self.layer2(x1)\n","        x3 = self.layer3(x2)\n","        x4 = self.layer4(x3)\n","        x5 = self.layer5(x4)\n","        \n","        cnn_feat = x5.squeeze(2) # [N, c, w]\n","        cnn_feat = cnn_feat.transpose(2, 1)\n","        \n","        return cnn_feat\n","\n","# decoder\n","class BidirectionalLSTM(nn.Module):\n","    def __init__(self, nIn=512, nHidden=512, nOut=512):\n","        super(BidirectionalLSTM, self).__init__()\n","        self.rnn = nn.LSTM(nIn, nHidden, bidirectional=True)\n","        self.embedding = nn.Linear(nHidden * 2, nOut)\n","        \n","    def forward(self, input):\n","        recurrent, _ = self.rnn(input)\n","        T, b, h = recurrent.size()\n","        t_rec = recurrent.view(T * b, h)\n","        output = self.embedding(t_rec)    # [T * b, nOut]\n","        output = output.view(T, b, -1)\n","        \n","        return output\n","\n","# basic\n","class RecModelBuilder(nn.Module):\n","    def __init__(self, rec_num_classes, sDim=512):\n","        super(RecModelBuilder, self).__init__()\n","        self.rec_num_classes = rec_num_classes\n","        self.sDim = sDim\n","        \n","        self.encoder = RecBackbone()\n","        self.decoder = nn.Sequential(\n","        BidirectionalLSTM(sDim, sDim, sDim),\n","        BidirectionalLSTM(sDim, sDim, rec_num_classes))\n","        \n","        self.rec_crit = nn.CTCLoss(zero_infinity=True)\n","        \n","    \n","    def forward(self, inputs):\n","        x, rec_targets, rec_lengths = inputs\n","        batch_size = x.shape[0]\n","        \n","        encoder_feats = self.encoder(x)   # N, T, C\n","        encoder_feats = encoder_feats.transpose(0, 1).contiguous() # T, N, C\n","        rec_pred = self.decoder(encoder_feats)\n","        \n","        if self.training:\n","            rec_pred = rec_pred.log_softmax(dim=2)\n","            preds_size = torch.IntTensor([rec_pred.size(0)] * batch_size)\n","            loss_rec = self.rec_crit(rec_pred, rec_targets, preds_size, rec_lengths)\n","            return loss_rec\n","        else:\n","            rec_pred_scores = torch.softmax(rec_pred.transpose(0, 1), dim=2)\n","            return rec_pred_scores"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y9Z9gb1pz2nW","executionInfo":{"status":"ok","timestamp":1621309661271,"user_tz":-480,"elapsed":2097,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"0d2ca2a8-6394-4ee9-c4d1-ed826b69c63c"},"source":["'''\n","模型各阶段数据结构展示\n","'''\n","dataset = WMRDataset(rec_args.train_dir, max_len=rec_args.max_len, resize_shape=(rec_args.height, rec_args.width), train=True)\n","train_dataloader = data.DataLoader(dataset, batch_size=2, num_workers=0, shuffle=True, pin_memory=True, drop_last=False)\n","batch = next(iter(train_dataloader))\n","\n","model = RecModelBuilder(rec_num_classes=rec_args.voc_size, sDim=rec_args.decoder_sdim)\n","model = model.to(device)\n","model.train()\n","\n","image, rec_targets, rec_lengths = [v.to(device) for v in batch]\n","encoder_out = model.encoder(image)\n","decoder_out = model.decoder(encoder_out.transpose(0, 1).contiguous())\n"," \n","\n","# batch 输入\n","print('batch 输入 [image, label, label_length]：')\n","print(batch[0].shape)\n","print(batch[1].shape)\n","print(batch[2].shape)\n","print()\n","\n","# encoder 输出\n","print('encoder 输出：')\n","print(encoder_out.shape)\n","print()\n","\n","# decoder 输出\n","print('decoder 输出：')\n","print(decoder_out.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["batch 输入 [image, label, label_length]：\n","torch.Size([2, 3, 32, 100])\n","torch.Size([2, 5])\n","torch.Size([2])\n","\n","encoder 输出：\n","torch.Size([2, 25, 512])\n","\n","decoder 输出：\n","torch.Size([25, 2, 21])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZN8X48bCz8GM"},"source":["# train\n","def rec_train():\n","    # dataset\n","    dataset = WMRDataset(rec_args.train_dir, max_len=rec_args.max_len, resize_shape=(rec_args.height, rec_args.width), train=True)\n","    train_dataloader = data.DataLoader(dataset, batch_size=rec_args.batch_size, num_workers=rec_args.num_workers, shuffle=True, pin_memory=True, drop_last=False)\n","    \n","    # model\n","    model = RecModelBuilder(rec_num_classes=rec_args.voc_size, sDim=rec_args.decoder_sdim)\n","    model = model.to(device)\n","    model.train()\n","    \n","    # Optimizer\n","    param_groups = filter(lambda p: p.requires_grad, model.parameters())\n","    optimizer = torch.optim.Adadelta(param_groups, lr=rec_args.lr)\n","    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=rec_args.milestones, gamma=0.1)\n","\n","    os.makedirs(rec_args.save_dir, exist_ok=True)\n","    # do train\n","    step = 2\n","    for epoch in range(rec_args.max_epoch):\n","        current_lr = optimizer.param_groups[0]['lr']\n","        \n","        for i, batch in enumerate(train_dataloader):\n","            step += 1\n","            batch = [v.to(device) for v in batch]\n","            loss = model(batch)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            # print\n","        if step % rec_args.print_interval == 0:\n","                print('step: {:4d}\\tepoch: {:4d}\\tloss: {:.4f}'.format(step, epoch, loss.item()))\n","        scheduler.step()\n","        \n","        # save\n","        save_name = 'checkpoint_' + str(epoch)\n","        torch.save(model.state_dict(), os.path.join(rec_args.save_dir, save_name))\n","\n","    torch.save(model.state_dict(), rec_args.saved_model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SiP8-rAX0Bfz","executionInfo":{"status":"ok","timestamp":1621310870499,"user_tz":-480,"elapsed":330749,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"945be65c-1afb-4030-c3c4-6d2d49dc1210"},"source":["# 运行训练代码\n","rec_train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["step:   50\tepoch:    2\tloss: 1.9379\n","step:  130\tepoch:    7\tloss: 1.6975\n","step:  210\tepoch:   12\tloss: 1.7950\n","step:  290\tepoch:   17\tloss: 1.7036\n","step:  370\tepoch:   22\tloss: 1.4804\n","step:  450\tepoch:   27\tloss: 1.0971\n","step:  530\tepoch:   32\tloss: 0.6519\n","step:  610\tepoch:   37\tloss: 0.4160\n","step:  690\tepoch:   42\tloss: 0.1216\n","step:  770\tepoch:   47\tloss: 0.0583\n","step:  850\tepoch:   52\tloss: 0.0380\n","step:  930\tepoch:   57\tloss: 0.0247\n","step: 1010\tepoch:   62\tloss: 0.0384\n","step: 1090\tepoch:   67\tloss: 0.0277\n","step: 1170\tepoch:   72\tloss: 0.0152\n","step: 1250\tepoch:   77\tloss: 0.0285\n","step: 1330\tepoch:   82\tloss: 0.0258\n","step: 1410\tepoch:   87\tloss: 0.0213\n","step: 1490\tepoch:   92\tloss: 0.0175\n","step: 1570\tepoch:   97\tloss: 0.0348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3rGxEG3N0PZm","executionInfo":{"status":"ok","timestamp":1621311293832,"user_tz":-480,"elapsed":139442,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"55c8242d-156e-409f-bd20-7cee4814e698"},"source":["'''\n","根据检测结果生成识别模型测试数据\n","'''\n","def rec_test_data_gen():\n","    test_dir = 'datasets/data/test_imgs'\n","    det_dir = 'temp/det_res'\n","    word_save_dir = 'temp/rec_datasets/test_imgs'\n","\n","    os.makedirs(word_save_dir, exist_ok=True)\n","    label_files = os.listdir(det_dir)\n","    for label_file in tqdm(label_files):\n","        if not label_file.endswith('.txt'):\n","            continue\n","        with open(os.path.join(det_dir, label_file), 'r') as f:\n","            lines = f.readlines()\n","        if len(lines) == 0:\n","            continue\n","        line = lines[0].strip().split(',')\n","        locs = [float(t) for t in line[:8]]\n","\n","        # image warp\n","        x1, y1, x2, y2, x3, y3, x4, y4 = locs\n","        w = int(0.5 * (((x2-x1)**2+(y2-y1)**2)**0.5 + ((x4-x3)**2+(y4-y3)**2)**0.5))\n","        h = int(0.5 * (((x2-x3)**2+(y2-y3)**2)**0.5 + ((x4-x1)**2+(y4-y1)**2)**0.5))\n","        src_points = np.array([[x1, y1], [x2, y2], [x3, y3], [x4, y4]], dtype='float32')\n","        dst_points = np.array([[0, 0], [w, 0], [w, h], [0, h]], dtype='float32')\n","        M = cv2.getPerspectiveTransform(src_points, dst_points)\n","        image = cv2.imread(os.path.join(test_dir, label_file.replace('det_res_', '')[:-4] + '.jpg'))\n","        word_image = cv2.warpPerspective(image, M, (w, h))\n","        \n","        # save images\n","        cv2.imwrite(os.path.join(word_save_dir, label_file.replace('det_res_', '')[:-4]+'.jpg'), word_image)\n","\n","# 使用检测模型获取识别测试数据\n","rec_test_data_gen()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["100%|██████████| 501/501 [02:18<00:00,  3.61it/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iLTx1fRO0bhw"},"source":["# inference\n","# 模型输出进行CTC对应解码，去除blank，将连续同字符合并\n","def rec_decode(rec_prob, labelmap, blank=0):\n","    raw_str = torch.max(rec_prob, dim=-1)[1].data.cpu().numpy()\n","    res_str = []\n","    for b in range(len(raw_str)):\n","        res_b = []\n","        prev = -1\n","        for ch in raw_str[b]:\n","            if ch == prev or ch == blank:\n","                prev = ch\n","                continue\n","            res_b.append(labelmap[ch])\n","            prev = ch\n","        res_str.append(''.join(res_b))\n","    return res_str\n","    \n","    \n","def rec_load_test_image(image_path, size=(100, 32)):\n","    img = Image.open(image_path)\n","    img = img.resize(size, Image.BILINEAR)\n","    img = torchvision.transforms.ToTensor()(img)\n","    img.sub_(0.5).div_(0.5)\n","    return img.unsqueeze(0)\n","\n","# 测试\n","def rec_test():\n","    model = RecModelBuilder(rec_num_classes=rec_args.voc_size, sDim=rec_args.decoder_sdim)\n","    model.load_state_dict(torch.load(rec_args.saved_model_path, map_location=device))\n","    model.eval()\n","    \n","    os.makedirs(rec_args.rec_res_dir, exist_ok=True)\n","    _, _, labelmap = WMRDataset().gen_labelmap()          # labelmap是类别和字符对应的字典\n","    with torch.no_grad():\n","        for file in tqdm(os.listdir(rec_args.test_dir)):\n","            img_path = os.path.join(rec_args.test_dir, file)\n","            image = rec_load_test_image(img_path)\n","            batch = [image, None, None]\n","            pred_prob = model.forward(batch)\n","            # todo post precess\n","            rec_str = rec_decode(pred_prob, labelmap)[0]\n","            # write to file\n","            with open(os.path.join(rec_args.rec_res_dir, file.replace('.jpg', '.txt')), 'w') as f:\n","                f.write(rec_str)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ITWeoBxc2YQW","executionInfo":{"status":"ok","timestamp":1621297681788,"user_tz":-480,"elapsed":1476,"user":{"displayName":"Ray Dragon","photoUrl":"","userId":"18063563590001153585"}},"outputId":"297963a7-7746-41cb-ff4f-7d3be1e2b86e"},"source":["ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bL0tGN7t0iYs"},"source":["# 运行测试代码\n","rec_test()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmXEAHN60u93"},"source":["'''\n","识别结果后处理\n","'''\n","def final_postProcess():\n","    SPECIAL_CHARS = {k:v for k, v in zip('ABCDEFGHIJ', '1234567890')}\n","\n","    test_dir = 'datasets/data/test_imgs'\n","    rec_res_dir = 'temp/rec_res'\n","    rec_res_files = os.listdir(rec_res_dir)\n","\n","    final_res = dict()\n","    for file in os.listdir(test_dir):\n","        res_file = file.replace('.jpg', '.txt')\n","        if res_file not in rec_res_files:\n","            final_res[file] = ''\n","            continue\n","        \n","        with open(os.path.join(rec_res_dir, res_file), 'r') as f:\n","            rec_res = f.readline().strip()\n","        final_res[file] = ''.join([t if t not in 'ABCDEFGHIJ' else SPECIAL_CHARS[t] for t in rec_res])\n","\n","    with open('work/final_res.txt', 'w') as f:\n","        for key, value in final_res.items():\n","            f.write(key + '\\t' + value + '\\n')\n","\n","\n","# 生成最终的测试结果\n","final_postProcess()"],"execution_count":null,"outputs":[]}]}